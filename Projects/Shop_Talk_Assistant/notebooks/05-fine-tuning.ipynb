{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ShopTalk – Embedding Fine-Tuning & Model Benchmarking\n",
        "\n",
        "**Project:** ShopTalk – AI-Powered Shopping Assistant  \n",
        "**Dataset:** [Amazon Berkeley Objects (ABO)](https://amazon-berkeley-objects.s3.amazonaws.com/index.html)  \n",
        "**Author:** Balaji Gurusala  \n",
        "**Notebook Scope:** Fine-tuning (requirements.md §5), Model Comparison, Vector Store Benchmarking  \n",
        "**Prerequisite:** `03-rag-prototype.ipynb` artifacts (rag_products.pkl, embeddings, rag_config.json)  \n",
        "**Environment:** Kaggle (CUDA – T4/P100 GPU required for training) or local with CUDA/MPS\n",
        "\n",
        "---\n",
        "\n",
        "### Purpose\n",
        "\n",
        "Per `requirements.md` §5 (Research & Academic Requirements):\n",
        "\n",
        "| Requirement | This Notebook |\n",
        "|------------|---------------|\n",
        "| **Triplet Loss** fine-tuning on ABO | Generate triplets by category, train with `TripletLoss` |\n",
        "| **Full fine-tuning** | Full parameter update (MiniLM is only 22M params — LoRA overhead not beneficial at this scale) |\n",
        "| **Base vs Fine-Tuned** comparison | Benchmark Precision@5 before/after fine-tuning |\n",
        "| **ChromaDB vs FAISS** comparison | Benchmark retrieval latency and throughput |\n",
        "\n",
        "> **Note on LoRA:** LoRA/QLoRA adapters are most beneficial for large models (>1B params) where full fine-tuning is memory-prohibitive. For `all-MiniLM-L6-v2` (22M params), full fine-tuning is more effective and runs easily on Kaggle T4 GPUs.\n",
        "\n",
        "### Pipeline\n",
        "\n",
        "```\n",
        "NB03 artifacts → Generate Triplets → Fine-Tune (Triplet Loss, full params)\n",
        "   → Evaluate Base vs Fine-Tuned (P@5) → Benchmark ChromaDB vs FAISS\n",
        "   → Export Fine-Tuned Model\n",
        "```\n",
        "\n",
        "### Outputs\n",
        "\n",
        "| Artifact | Description |\n",
        "|----------|-------------|\n",
        "| `models/finetuned-shoptalk-emb/` | Fine-tuned SentenceTransformer model |\n",
        "| `finetuned_text_index.npy` | Re-embedded product index with fine-tuned model |\n",
        "| `finetune_results.json` | Training metrics, P@5 comparison, benchmark results |\n",
        "| `finetune_evaluation.csv` | Detailed per-query evaluation results |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 0 – Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 0: Environment Setup\n",
        "# ============================================================\n",
        "import sys, os, json, time, re, warnings, random\n",
        "from pathlib import Path\n",
        "from typing import Optional, List, Dict, Tuple\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "print(f\"Python {sys.version}\")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DEVICE = (\n",
        "    \"cuda\" if torch.cuda.is_available() else\n",
        "    \"mps\" if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() else\n",
        "    \"cpu\"\n",
        ")\n",
        "GPU_NAME = torch.cuda.get_device_name(0) if DEVICE == \"cuda\" else DEVICE\n",
        "print(f\"PyTorch {torch.__version__}\")\n",
        "print(f\"Device: {DEVICE} ({GPU_NAME})\")\n",
        "\n",
        "ON_KAGGLE = Path(\"/kaggle/working\").exists()\n",
        "print(f\"Platform: {'Kaggle' if ON_KAGGLE else 'Local'}\")\n",
        "\n",
        "# Install deps\n",
        "def _install(*pkgs):\n",
        "    import subprocess\n",
        "    for pkg in pkgs:\n",
        "        try:\n",
        "            __import__(pkg.split(\"==\")[0].replace(\"-\", \"_\"))\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "_install(\"sentence-transformers\", \"faiss-cpu\", \"chromadb\")\n",
        "\n",
        "print(\"\\n\\u2713 Environment ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 1 – Load Data & Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 1: Load NB03 Artifacts\n",
        "# ============================================================\n",
        "\n",
        "_candidates = [\n",
        "    Path(\"/kaggle/input/shoptalk-rag-prototype\"),\n",
        "    Path(\"/kaggle/working\"),\n",
        "    Path(\"../data\"),\n",
        "    Path(\".\"),\n",
        "]\n",
        "DATA_DIR = None\n",
        "for d in _candidates:\n",
        "    if (d / \"rag_products.pkl\").exists():\n",
        "        DATA_DIR = d\n",
        "        break\n",
        "assert DATA_DIR is not None, \"Cannot find NB03 artifacts. Run 03-rag-prototype.ipynb first.\"\n",
        "\n",
        "EXPORT_DIR = Path(\"/kaggle/working\") if ON_KAGGLE else Path(\"../data\")\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_DIR = EXPORT_DIR / \"models\" / \"finetuned-shoptalk-emb\"\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Data directory:   {DATA_DIR}\")\n",
        "print(f\"Export directory:  {EXPORT_DIR}\")\n",
        "print(f\"Model directory:  {MODEL_DIR}\")\n",
        "\n",
        "# Load data\n",
        "df = pd.read_pickle(DATA_DIR / \"rag_products.pkl\")\n",
        "TEXT_INDEX_BASE = np.load(DATA_DIR / \"rag_text_index.npy\")\n",
        "IMAGE_INDEX = np.load(DATA_DIR / \"rag_image_index.npy\")\n",
        "\n",
        "with open(DATA_DIR / \"rag_config.json\") as f:\n",
        "    RAG_CONFIG = json.load(f)\n",
        "\n",
        "print(f\"\\nProducts:    {len(df):,}\")\n",
        "print(f\"Text index:  {TEXT_INDEX_BASE.shape}\")\n",
        "print(f\"Image index: {IMAGE_INDEX.shape}\")\n",
        "print(f\"Categories:  {df['product_type_flat'].nunique()}\")\n",
        "\n",
        "# Category distribution\n",
        "cat_counts = df[\"product_type_flat\"].value_counts()\n",
        "print(f\"\\nTop 10 categories:\")\n",
        "for cat, cnt in cat_counts.head(10).items():\n",
        "    print(f\"  {cat:35s}  {cnt:5d}\")\n",
        "\n",
        "print(f\"\\n\\u2713 Artifacts loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2 – Generate Training Triplets\n",
        "\n",
        "Per `requirements.md`: *\"Use Triplet Loss to train the embedding model on the ABO dataset.\"*\n",
        "\n",
        "**Triplet structure:**  \n",
        "- **Anchor**: Product enriched text  \n",
        "- **Positive**: Another product in the SAME category  \n",
        "- **Negative**: A product from a DIFFERENT category  \n",
        "\n",
        "This teaches the model that products in the same category should be closer  \n",
        "in embedding space than products from different categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 2: Generate Training Triplets\n",
        "# ============================================================\n",
        "\n",
        "from sentence_transformers import InputExample\n",
        "\n",
        "# Group products by category\n",
        "category_products = defaultdict(list)\n",
        "for idx, row in df.iterrows():\n",
        "    cat = row.get(\"product_type_flat\", \"UNKNOWN\")\n",
        "    text = str(row.get(\"enriched_text\", \"\"))\n",
        "    if cat and text and len(text) > 20:\n",
        "        category_products[cat].append((idx, text))\n",
        "\n",
        "# Filter categories with at least 2 products (needed for positive pairs)\n",
        "valid_categories = {k: v for k, v in category_products.items() if len(v) >= 2}\n",
        "all_categories = list(valid_categories.keys())\n",
        "\n",
        "print(f\"Valid categories (>= 2 products): {len(valid_categories)}\")\n",
        "print(f\"Total products in valid categories: {sum(len(v) for v in valid_categories.values()):,}\")\n",
        "\n",
        "# --- Generate triplets ---\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "NUM_TRIPLETS = 20000  # Target number of triplets\n",
        "HARD_NEGATIVE_RATIO = 0.3  # 30% hard negatives (similar categories)\n",
        "\n",
        "# Build hard negative map (categories that are semantically similar)\n",
        "SIMILAR_CATEGORIES = {\n",
        "    \"SHOES\": [\"SANDAL\", \"BOOTS\"],\n",
        "    \"SHIRT\": [\"T_SHIRT\", \"POLO\"],\n",
        "    \"T_SHIRT\": [\"SHIRT\"],\n",
        "    \"HOME\": [\"HOME_BED_AND_BATH\", \"FURNITURE\"],\n",
        "    \"HOME_BED_AND_BATH\": [\"HOME\"],\n",
        "    \"HARDWARE\": [\"HARDWARE_HANDLE\"],\n",
        "    \"HARDWARE_HANDLE\": [\"HARDWARE\"],\n",
        "    \"CHAIR\": [\"OTTOMAN\", \"FURNITURE\"],\n",
        "    \"TABLE\": [\"FURNITURE\"],\n",
        "    \"OTTOMAN\": [\"CHAIR\", \"FURNITURE\"],\n",
        "}\n",
        "\n",
        "triplets = []\n",
        "triplet_texts = []  # For InputExample format\n",
        "\n",
        "for _ in range(NUM_TRIPLETS):\n",
        "    # Pick anchor category\n",
        "    anchor_cat = random.choice(all_categories)\n",
        "    anchor_products = valid_categories[anchor_cat]\n",
        "\n",
        "    # Pick anchor and positive (same category, different product)\n",
        "    anchor_idx, positive_idx = random.sample(range(len(anchor_products)), 2)\n",
        "    anchor_text = anchor_products[anchor_idx][1]\n",
        "    positive_text = anchor_products[positive_idx][1]\n",
        "\n",
        "    # Pick negative (different category)\n",
        "    use_hard = random.random() < HARD_NEGATIVE_RATIO\n",
        "    if use_hard and anchor_cat in SIMILAR_CATEGORIES:\n",
        "        # Hard negative: from a similar category\n",
        "        hard_cats = [c for c in SIMILAR_CATEGORIES[anchor_cat] if c in valid_categories]\n",
        "        if hard_cats:\n",
        "            neg_cat = random.choice(hard_cats)\n",
        "        else:\n",
        "            neg_cat = random.choice([c for c in all_categories if c != anchor_cat])\n",
        "    else:\n",
        "        # Random negative: from any different category\n",
        "        neg_cat = random.choice([c for c in all_categories if c != anchor_cat])\n",
        "\n",
        "    neg_products = valid_categories[neg_cat]\n",
        "    negative_text = random.choice(neg_products)[1]\n",
        "\n",
        "    triplets.append((anchor_text, positive_text, negative_text))\n",
        "    triplet_texts.append(InputExample(\n",
        "        texts=[anchor_text, positive_text, negative_text]\n",
        "    ))\n",
        "\n",
        "print(f\"\\n\\u2713 Generated {len(triplets):,} triplets\")\n",
        "print(f\"  Hard negatives: ~{HARD_NEGATIVE_RATIO*100:.0f}%\")\n",
        "print(f\"  Anchor text sample: {triplets[0][0][:100]}...\")\n",
        "print(f\"  Positive sample:    {triplets[0][1][:100]}...\")\n",
        "print(f\"  Negative sample:    {triplets[0][2][:100]}...\")\n",
        "\n",
        "# Train/val split\n",
        "split_idx = int(len(triplet_texts) * 0.9)\n",
        "train_examples = triplet_texts[:split_idx]\n",
        "val_examples = triplet_texts[split_idx:]\n",
        "print(f\"\\n  Train: {len(train_examples):,} | Val: {len(val_examples):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3 – Fine-Tune Embedding Model\n",
        "\n",
        "Fine-tune `all-MiniLM-L6-v2` with **TripletLoss** (full parameter update).  \n",
        "MiniLM is compact (22M params) so full fine-tuning runs efficiently on Kaggle T4 GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 3: Fine-Tune with Triplet Loss\n",
        "# ============================================================\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, losses, evaluation\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BASE_MODEL_ID = RAG_CONFIG.get(\"text_model_id\", \"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Load base model ---\n",
        "print(f\"Loading base model: {BASE_MODEL_ID}\")\n",
        "ft_model = SentenceTransformer(BASE_MODEL_ID, device=DEVICE)\n",
        "print(f\"  Parameters: {sum(p.numel() for p in ft_model.parameters()):,}\")\n",
        "\n",
        "# --- Training config ---\n",
        "BATCH_SIZE = 64 if DEVICE == \"cuda\" else 16\n",
        "NUM_EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "WARMUP_RATIO = 0.1\n",
        "MARGIN = 0.5  # Triplet margin\n",
        "\n",
        "# --- DataLoader ---\n",
        "train_dataloader = DataLoader(\n",
        "    train_examples,\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "# --- Loss function ---\n",
        "train_loss = losses.TripletLoss(\n",
        "    model=ft_model,\n",
        "    distance_metric=losses.TripletDistanceMetric.COSINE,\n",
        "    triplet_margin=MARGIN,\n",
        ")\n",
        "\n",
        "# --- Evaluator (using val set) ---\n",
        "# Create evaluation anchors, positives, negatives\n",
        "val_anchors = [ex.texts[0] for ex in val_examples[:500]]\n",
        "val_positives = [ex.texts[1] for ex in val_examples[:500]]\n",
        "val_negatives = [ex.texts[2] for ex in val_examples[:500]]\n",
        "\n",
        "val_evaluator = evaluation.TripletEvaluator(\n",
        "    anchors=val_anchors,\n",
        "    positives=val_positives,\n",
        "    negatives=val_negatives,\n",
        "    name=\"shoptalk-val\",\n",
        "    main_distance_function=evaluation.TripletEvaluator.SimilarityFunction.COSINE,\n",
        ")\n",
        "\n",
        "# --- Training ---\n",
        "warmup_steps = int(len(train_dataloader) * NUM_EPOCHS * WARMUP_RATIO)\n",
        "\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"  Batch size:    {BATCH_SIZE}\")\n",
        "print(f\"  Epochs:        {NUM_EPOCHS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  Warmup steps:  {warmup_steps}\")\n",
        "print(f\"  Triplet margin:{MARGIN}\")\n",
        "print(f\"  Train batches: {len(train_dataloader)}\")\n",
        "print(f\"  Device:        {DEVICE}\")\n",
        "\n",
        "print(f\"\\nStarting fine-tuning...\")\n",
        "t_start = time.time()\n",
        "\n",
        "ft_model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    evaluator=val_evaluator,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    warmup_steps=warmup_steps,\n",
        "    optimizer_params={\"lr\": LEARNING_RATE},\n",
        "    output_path=str(MODEL_DIR),\n",
        "    evaluation_steps=len(train_dataloader) // 2,\n",
        "    save_best_model=True,\n",
        "    show_progress_bar=True,\n",
        ")\n",
        "\n",
        "train_time = time.time() - t_start\n",
        "print(f\"\\n\\u2713 Fine-tuning complete in {train_time:.1f}s ({train_time/60:.1f} min)\")\n",
        "print(f\"  Model saved to: {MODEL_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 4 – Re-Embed Products with Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 4: Re-Embed with Fine-Tuned Model\n",
        "# ============================================================\n",
        "\n",
        "print(\"Loading fine-tuned model...\")\n",
        "ft_model = SentenceTransformer(str(MODEL_DIR), device=DEVICE)\n",
        "print(f\"  Parameters: {sum(p.numel() for p in ft_model.parameters()):,}\")\n",
        "\n",
        "# Also load base model for comparison\n",
        "print(f\"Loading base model: {BASE_MODEL_ID}\")\n",
        "base_model = SentenceTransformer(BASE_MODEL_ID, device=DEVICE)\n",
        "\n",
        "# --- Re-embed all products ---\n",
        "texts = df[\"enriched_text\"].fillna(\"\").tolist()\n",
        "\n",
        "print(f\"\\nEmbedding {len(texts):,} products with fine-tuned model...\")\n",
        "t0 = time.time()\n",
        "ft_embeddings = ft_model.encode(\n",
        "    texts,\n",
        "    batch_size=256 if DEVICE == \"cuda\" else 64,\n",
        "    show_progress_bar=True,\n",
        "    normalize_embeddings=True,\n",
        ")\n",
        "ft_embed_time = time.time() - t0\n",
        "TEXT_INDEX_FT = ft_embeddings.astype(np.float32)\n",
        "\n",
        "print(f\"\\n\\u2713 Fine-tuned embeddings: {TEXT_INDEX_FT.shape} in {ft_embed_time:.1f}s\")\n",
        "\n",
        "# Save\n",
        "ft_index_path = EXPORT_DIR / \"finetuned_text_index.npy\"\n",
        "np.save(ft_index_path, TEXT_INDEX_FT)\n",
        "print(f\"\\u2713 Saved to {ft_index_path.name} ({ft_index_path.stat().st_size / 1e6:.1f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 5 – Evaluate: Base vs Fine-Tuned (Precision@5)\n",
        "\n",
        "Per `requirements.md`: *\"Benchmark retrieval precision of Base Embedding Model vs. Fine-Tuned Model.\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 5: Precision@5 Evaluation — Base vs Fine-Tuned\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_precision_at_k(\n",
        "    text_index: np.ndarray,\n",
        "    image_index: np.ndarray,\n",
        "    df_data: pd.DataFrame,\n",
        "    alpha: float = 0.6,\n",
        "    k: int = 5,\n",
        "    n_queries: int = 200,\n",
        "    seed: int = 42,\n",
        ") -> Dict:\n",
        "    \"\"\"Evaluate P@K: fraction of top-K results sharing the query's category.\"\"\"\n",
        "    rng = np.random.RandomState(seed)\n",
        "    categories = df_data[\"product_type_flat\"].values\n",
        "    valid_mask = pd.notna(categories)\n",
        "    valid_indices = np.where(valid_mask)[0]\n",
        "\n",
        "    if len(valid_indices) < n_queries:\n",
        "        n_queries = len(valid_indices)\n",
        "\n",
        "    query_indices = rng.choice(valid_indices, size=n_queries, replace=False)\n",
        "\n",
        "    precisions = []\n",
        "    for qi in query_indices:\n",
        "        q_text = text_index[qi:qi+1]\n",
        "        q_image = image_index[qi:qi+1]\n",
        "\n",
        "        text_sim = (text_index @ q_text.T).squeeze()\n",
        "        image_sim = (image_index @ q_image.T).squeeze()\n",
        "        scores = alpha * text_sim + (1.0 - alpha) * image_sim\n",
        "        scores[qi] = -np.inf  # Exclude self\n",
        "\n",
        "        top_k_idx = np.argsort(scores)[::-1][:k]\n",
        "        query_cat = categories[qi]\n",
        "        hits = sum(1 for idx in top_k_idx if categories[idx] == query_cat)\n",
        "        precisions.append(hits / k)\n",
        "\n",
        "    return {\n",
        "        \"mean_p_at_k\": np.mean(precisions),\n",
        "        \"std_p_at_k\": np.std(precisions),\n",
        "        \"median_p_at_k\": np.median(precisions),\n",
        "        \"n_queries\": n_queries,\n",
        "        \"k\": k,\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Evaluate both models ---\n",
        "N_EVAL = 200\n",
        "\n",
        "print(f\"Evaluating P@5 with {N_EVAL} queries...\\n\")\n",
        "\n",
        "# Base model\n",
        "t0 = time.time()\n",
        "base_results = evaluate_precision_at_k(\n",
        "    TEXT_INDEX_BASE, IMAGE_INDEX, df, alpha=0.6, n_queries=N_EVAL\n",
        ")\n",
        "base_eval_time = time.time() - t0\n",
        "\n",
        "# Fine-tuned model\n",
        "t0 = time.time()\n",
        "ft_results = evaluate_precision_at_k(\n",
        "    TEXT_INDEX_FT, IMAGE_INDEX, df, alpha=0.6, n_queries=N_EVAL\n",
        ")\n",
        "ft_eval_time = time.time() - t0\n",
        "\n",
        "# --- Alpha sweep for fine-tuned ---\n",
        "print(\"Running alpha sweep for fine-tuned model...\")\n",
        "alpha_sweep_ft = []\n",
        "for alpha in np.arange(0.0, 1.05, 0.1):\n",
        "    r = evaluate_precision_at_k(TEXT_INDEX_FT, IMAGE_INDEX, df, alpha=alpha, n_queries=100)\n",
        "    alpha_sweep_ft.append({\"alpha\": round(alpha, 1), \"P@5\": r[\"mean_p_at_k\"]})\n",
        "\n",
        "df_sweep_ft = pd.DataFrame(alpha_sweep_ft)\n",
        "best_ft = df_sweep_ft.loc[df_sweep_ft[\"P@5\"].idxmax()]\n",
        "\n",
        "# --- Results ---\n",
        "print(f\"\\n{'=' * 70}\")\n",
        "print(\"PRECISION@5 COMPARISON: Base vs Fine-Tuned\")\n",
        "print(f\"{'=' * 70}\")\n",
        "print(f\"\\n  Base Model ({BASE_MODEL_ID}):\")\n",
        "print(f\"    P@5 = {base_results['mean_p_at_k']:.4f} \\u00b1 {base_results['std_p_at_k']:.4f}\")\n",
        "print(f\"    Eval time: {base_eval_time:.2f}s\")\n",
        "print(f\"\\n  Fine-Tuned Model:\")\n",
        "print(f\"    P@5 = {ft_results['mean_p_at_k']:.4f} \\u00b1 {ft_results['std_p_at_k']:.4f}\")\n",
        "print(f\"    Eval time: {ft_eval_time:.2f}s\")\n",
        "print(f\"    Best alpha (sweep): {best_ft['alpha']:.1f} -> P@5 = {best_ft['P@5']:.4f}\")\n",
        "\n",
        "improvement = ft_results['mean_p_at_k'] - base_results['mean_p_at_k']\n",
        "pct_improvement = improvement / base_results['mean_p_at_k'] * 100\n",
        "print(f\"\\n  \\u0394 P@5: {improvement:+.4f} ({pct_improvement:+.1f}%)\")\n",
        "_ft_verdict = \"✅ Fine-tuning improved retrieval!\" if improvement > 0 else \"⚠ No improvement (try more epochs or larger dataset)\"\n",
        "print(f\"  {_ft_verdict}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 6 – Vector Store Benchmark: ChromaDB vs FAISS\n",
        "\n",
        "Per `requirements.md`: *\"Compare latency/throughput of ChromaDB vs. Milvus (or FAISS).\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 6: ChromaDB vs FAISS Benchmark\n",
        "# ============================================================\n",
        "\n",
        "import faiss\n",
        "import chromadb\n",
        "\n",
        "# Use fine-tuned embeddings for the benchmark\n",
        "BENCH_INDEX = TEXT_INDEX_FT\n",
        "N_PRODUCTS = BENCH_INDEX.shape[0]\n",
        "EMBED_DIM = BENCH_INDEX.shape[1]\n",
        "N_QUERIES = 100\n",
        "TOP_K = 5\n",
        "\n",
        "# Generate random query embeddings (simulating search queries)\n",
        "np.random.seed(42)\n",
        "query_indices = np.random.choice(N_PRODUCTS, size=N_QUERIES, replace=False)\n",
        "query_embeddings = BENCH_INDEX[query_indices]\n",
        "\n",
        "print(f\"Benchmark setup: {N_PRODUCTS:,} products, {EMBED_DIM}d, {N_QUERIES} queries, top-{TOP_K}\")\n",
        "\n",
        "# ============================================================\n",
        "# FAISS Benchmark\n",
        "# ============================================================\n",
        "\n",
        "# --- FAISS Flat (exact) ---\n",
        "print(\"\\n--- FAISS (Flat, exact search) ---\")\n",
        "t0 = time.time()\n",
        "faiss_flat = faiss.IndexFlatIP(EMBED_DIM)  # Inner product (cosine for normalized vectors)\n",
        "faiss_flat.add(BENCH_INDEX)\n",
        "faiss_build_flat = time.time() - t0\n",
        "print(f\"  Index build: {faiss_build_flat:.3f}s\")\n",
        "\n",
        "t0 = time.time()\n",
        "for qe in query_embeddings:\n",
        "    faiss_flat.search(qe.reshape(1, -1), TOP_K)\n",
        "faiss_query_flat = time.time() - t0\n",
        "faiss_qps_flat = N_QUERIES / faiss_query_flat\n",
        "print(f\"  Query time:  {faiss_query_flat:.3f}s total | {faiss_query_flat/N_QUERIES*1000:.2f}ms/query\")\n",
        "print(f\"  QPS:         {faiss_qps_flat:.0f}\")\n",
        "\n",
        "# --- FAISS IVF (approximate) ---\n",
        "print(\"\\n--- FAISS (IVF, approximate search) ---\")\n",
        "n_clusters = min(100, N_PRODUCTS // 10)\n",
        "quantizer = faiss.IndexFlatIP(EMBED_DIM)\n",
        "faiss_ivf = faiss.IndexIVFFlat(quantizer, EMBED_DIM, n_clusters, faiss.METRIC_INNER_PRODUCT)\n",
        "\n",
        "t0 = time.time()\n",
        "faiss_ivf.train(BENCH_INDEX)\n",
        "faiss_ivf.add(BENCH_INDEX)\n",
        "faiss_build_ivf = time.time() - t0\n",
        "faiss_ivf.nprobe = 10\n",
        "print(f\"  Index build: {faiss_build_ivf:.3f}s ({n_clusters} clusters)\")\n",
        "\n",
        "t0 = time.time()\n",
        "for qe in query_embeddings:\n",
        "    faiss_ivf.search(qe.reshape(1, -1), TOP_K)\n",
        "faiss_query_ivf = time.time() - t0\n",
        "faiss_qps_ivf = N_QUERIES / faiss_query_ivf\n",
        "print(f\"  Query time:  {faiss_query_ivf:.3f}s total | {faiss_query_ivf/N_QUERIES*1000:.2f}ms/query\")\n",
        "print(f\"  QPS:         {faiss_qps_ivf:.0f}\")\n",
        "\n",
        "# ============================================================\n",
        "# ChromaDB Benchmark\n",
        "# ============================================================\n",
        "print(\"\\n--- ChromaDB (Persistent) ---\")\n",
        "\n",
        "chroma_bench_dir = EXPORT_DIR / \"chroma_bench\"\n",
        "chroma_bench_dir.mkdir(exist_ok=True)\n",
        "\n",
        "t0 = time.time()\n",
        "chroma_client = chromadb.PersistentClient(path=str(chroma_bench_dir))\n",
        "\n",
        "# Delete existing collection if present\n",
        "try:\n",
        "    chroma_client.delete_collection(\"bench_text\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "collection = chroma_client.create_collection(\n",
        "    name=\"bench_text\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"},\n",
        ")\n",
        "\n",
        "# Upsert in batches\n",
        "CHROMA_BATCH = 1024\n",
        "ids = [str(i) for i in range(N_PRODUCTS)]\n",
        "for start in range(0, N_PRODUCTS, CHROMA_BATCH):\n",
        "    end = min(start + CHROMA_BATCH, N_PRODUCTS)\n",
        "    collection.add(\n",
        "        ids=ids[start:end],\n",
        "        embeddings=BENCH_INDEX[start:end].tolist(),\n",
        "    )\n",
        "chroma_build = time.time() - t0\n",
        "print(f\"  Index build: {chroma_build:.3f}s\")\n",
        "\n",
        "t0 = time.time()\n",
        "for qe in query_embeddings:\n",
        "    collection.query(query_embeddings=[qe.tolist()], n_results=TOP_K)\n",
        "chroma_query = time.time() - t0\n",
        "chroma_qps = N_QUERIES / chroma_query\n",
        "print(f\"  Query time:  {chroma_query:.3f}s total | {chroma_query/N_QUERIES*1000:.2f}ms/query\")\n",
        "print(f\"  QPS:         {chroma_qps:.0f}\")\n",
        "\n",
        "# Cleanup\n",
        "import shutil\n",
        "shutil.rmtree(chroma_bench_dir, ignore_errors=True)\n",
        "\n",
        "# ============================================================\n",
        "# Summary\n",
        "# ============================================================\n",
        "print(f\"\\n{'=' * 70}\")\n",
        "print(\"VECTOR STORE BENCHMARK SUMMARY\")\n",
        "print(f\"{'=' * 70}\")\n",
        "print(f\"{'Backend':25s} {'Build (s)':>10s} {'Query (ms)':>12s} {'QPS':>8s}\")\n",
        "_LINE = \"─\" * 55\n",
        "print(_LINE)\n",
        "print(f\"{'FAISS Flat (exact)':25s} {faiss_build_flat:>10.3f} {faiss_query_flat/N_QUERIES*1000:>12.2f} {faiss_qps_flat:>8.0f}\")\n",
        "print(f\"{'FAISS IVF (approx)':25s} {faiss_build_ivf:>10.3f} {faiss_query_ivf/N_QUERIES*1000:>12.2f} {faiss_qps_ivf:>8.0f}\")\n",
        "print(f\"{'ChromaDB (persistent)':25s} {chroma_build:>10.3f} {chroma_query/N_QUERIES*1000:>12.2f} {chroma_qps:>8.0f}\")\n",
        "\n",
        "benchmark_results = {\n",
        "    \"faiss_flat\": {\"build_s\": faiss_build_flat, \"query_ms\": faiss_query_flat/N_QUERIES*1000, \"qps\": faiss_qps_flat},\n",
        "    \"faiss_ivf\": {\"build_s\": faiss_build_ivf, \"query_ms\": faiss_query_ivf/N_QUERIES*1000, \"qps\": faiss_qps_ivf},\n",
        "    \"chromadb\": {\"build_s\": chroma_build, \"query_ms\": chroma_query/N_QUERIES*1000, \"qps\": chroma_qps},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 7 – Export Results & Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Step 7: Export Everything\n",
        "# ============================================================\n",
        "\n",
        "# 1. Save comprehensive results\n",
        "results = {\n",
        "    \"notebook\": \"05-fine-tuning\",\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"base_model\": BASE_MODEL_ID,\n",
        "    \"finetuned_model_path\": str(MODEL_DIR),\n",
        "    \"training\": {\n",
        "        \"n_triplets\": len(triplets),\n",
        "        \"n_train\": len(train_examples),\n",
        "        \"n_val\": len(val_examples),\n",
        "        \"epochs\": NUM_EPOCHS,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"triplet_margin\": MARGIN,\n",
        "        \"hard_negative_ratio\": HARD_NEGATIVE_RATIO,\n",
        "        \"train_time_s\": round(train_time, 1),\n",
        "    },\n",
        "    \"evaluation\": {\n",
        "        \"n_queries\": N_EVAL,\n",
        "        \"base_p_at_5\": round(float(base_results[\"mean_p_at_k\"]), 4),\n",
        "        \"base_p_at_5_std\": round(float(base_results[\"std_p_at_k\"]), 4),\n",
        "        \"finetuned_p_at_5\": round(float(ft_results[\"mean_p_at_k\"]), 4),\n",
        "        \"finetuned_p_at_5_std\": round(float(ft_results[\"std_p_at_k\"]), 4),\n",
        "        \"improvement\": round(float(improvement), 4),\n",
        "        \"improvement_pct\": round(float(pct_improvement), 1),\n",
        "        \"best_ft_alpha\": round(float(best_ft[\"alpha\"]), 1),\n",
        "        \"best_ft_p_at_5\": round(float(best_ft[\"P@5\"]), 4),\n",
        "    },\n",
        "    \"vector_store_benchmark\": benchmark_results,\n",
        "    \"device\": str(DEVICE),\n",
        "    \"gpu_name\": GPU_NAME,\n",
        "}\n",
        "\n",
        "results_path = EXPORT_DIR / \"finetune_results.json\"\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=2, default=str)\n",
        "print(f\"\\u2713 {results_path.name:35s}  {results_path.stat().st_size / 1e3:.1f} KB\")\n",
        "\n",
        "# 2. Alpha sweep results\n",
        "sweep_path = EXPORT_DIR / \"finetune_alpha_sweep.csv\"\n",
        "df_sweep_ft.to_csv(sweep_path, index=False)\n",
        "print(f\"\\u2713 {sweep_path.name:35s}  {sweep_path.stat().st_size / 1e3:.1f} KB\")\n",
        "\n",
        "# 3. Fine-tuned embeddings (already saved above)\n",
        "print(f\"\\u2713 {'finetuned_text_index.npy':35s}  {ft_index_path.stat().st_size / 1e6:.1f} MB\")\n",
        "\n",
        "# 4. Model directory listing\n",
        "print(f\"\\nFine-tuned model files in {MODEL_DIR}/:\")\n",
        "for p in sorted(MODEL_DIR.rglob(\"*\")):\n",
        "    if p.is_file():\n",
        "        print(f\"  {p.relative_to(MODEL_DIR)}  {p.stat().st_size / 1e6:.1f} MB\")\n",
        "\n",
        "print(f\"\\n\\u2713 All artifacts exported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Final Summary\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SHOPTALK FINE-TUNING \\u2014 SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n--- Training ---\")\n",
        "print(f\"  Base model:       {BASE_MODEL_ID}\")\n",
        "print(f\"  Triplets:         {len(triplets):,}\")\n",
        "print(f\"  Epochs:           {NUM_EPOCHS}\")\n",
        "print(f\"  Training time:    {train_time:.1f}s\")\n",
        "print(f\"  Device:           {DEVICE} ({GPU_NAME})\")\n",
        "\n",
        "print(\"\\n--- Retrieval Quality (P@5) ---\")\n",
        "print(f\"  Base model:       {base_results['mean_p_at_k']:.4f}\")\n",
        "print(f\"  Fine-tuned:       {ft_results['mean_p_at_k']:.4f}\")\n",
        "print(f\"  Improvement:      {improvement:+.4f} ({pct_improvement:+.1f}%)\")\n",
        "\n",
        "print(\"\\n--- Vector Store Benchmark ---\")\n",
        "print(f\"  FAISS Flat:       {faiss_query_flat/N_QUERIES*1000:.2f}ms/query  ({faiss_qps_flat:.0f} QPS)\")\n",
        "print(f\"  FAISS IVF:        {faiss_query_ivf/N_QUERIES*1000:.2f}ms/query  ({faiss_qps_ivf:.0f} QPS)\")\n",
        "print(f\"  ChromaDB:         {chroma_query/N_QUERIES*1000:.2f}ms/query  ({chroma_qps:.0f} QPS)\")\n",
        "\n",
        "print(\"\\n--- Exports ---\")\n",
        "print(f\"  Fine-tuned model: {MODEL_DIR}\")\n",
        "print(f\"  Embeddings:       finetuned_text_index.npy\")\n",
        "print(f\"  Results:          finetune_results.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Fine-tuning complete. Model ready for production use.\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbformat_minor": 4,
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
