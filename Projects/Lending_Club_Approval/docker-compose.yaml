version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      retries: 5

  mlflow:
    image: python:3.11-slim
    ports:
      - "5000:5000"
    # Install matching MLflow version and start server
    command: >
      sh -c "pip install mlflow==3.9.0 psycopg2-binary && 
             mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlartifacts --host 0.0.0.0"
    volumes:
      - ./mlruns:/mlflow/mlruns
      - ./mlartifacts:/mlartifacts
      - ./mlflow.db:/mlflow.db

  airflow-init:
    build: ./docker/airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      postgres:
        condition: service_healthy
    entrypoint: /bin/bash
    # Initialize DB and create default user
    command: -c "airflow db init && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin"

  airflow-webserver:
    build: ./docker/airflow
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./feature_repo:/opt/airflow/feature_repo
      - ./requirements.txt:/opt/airflow/requirements.txt
    ports:
      - "8080:8080"
    command: webserver

  airflow-scheduler:
    build: ./docker/airflow
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - PYTHONPATH=/opt/airflow:/opt/airflow/src
      - PROJECT_HOME=/opt/airflow
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./feature_repo:/opt/airflow/feature_repo
      - ./requirements.txt:/opt/airflow/requirements.txt
      # Mount models to save artifacts accessible to host/FastAPI
      - ./models:/opt/airflow/models 
    command: scheduler

  fastapi-app:
    build: .
    restart: always
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - UPLOAD_TO_S3=false
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./feature_repo:/app/feature_repo
    depends_on:
      - mlflow